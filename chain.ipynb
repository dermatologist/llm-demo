{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including GoogleGenerativeAI, PromptTemplate, StrOutputParser, RunnablePassthrough, and RunnableParallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beapen/venv/genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# Initialize the GoogleGenerativeAI model\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Language Model\n",
    "Initialize the GoogleGenerativeAI language model with the specified model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GoogleGenerativeAI language model with the specified model version\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Summary Template\n",
    "Define the template for generating case summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for generating case summaries\n",
    "SUMMARY_TEMPLATE = \"\"\"\n",
    "You are a medical AI assistant that generates case summaries.\n",
    "Generate a case summary for {question}:\n",
    "case summary::\"\"\"\n",
    "\n",
    "# Create a PromptTemplate from the SUMMARY_TEMPLATE\n",
    "SUMMARY_PROMPT = PromptTemplate.from_template(SUMMARY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Summary Prompt\n",
    "Create a PromptTemplate instance from the summary template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Summary Prompt\n",
    "# Create a PromptTemplate instance from the summary template\n",
    "SUMMARY_PROMPT = PromptTemplate.from_template(SUMMARY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Question Template\n",
    "Define the template for answering queries based on the case summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for answering queries based on the case summary\n",
    "QUESTION_TEMPLATE = \"\"\"\n",
    "Given the case summary below, answer the query.\n",
    "Case Summary: {case_summary}\n",
    "Query: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Create a PromptTemplate from the QUESTION_TEMPLATE\n",
    "QUESTION_PROMPT = PromptTemplate.from_template(QUESTION_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Question Prompt\n",
    "Create a PromptTemplate instance from the question template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Question Prompt\n",
    "# Create a PromptTemplate instance from the question template\n",
    "QUESTION_PROMPT = PromptTemplate.from_template(QUESTION_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Summary Runnable\n",
    "Create a RunnablePassthrough instance that processes the summary prompt through the language model and parses the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Summary Runnable\n",
    "# Create a RunnablePassthrough instance that processes the summary prompt through the language model and parses the output\n",
    "summary = RunnablePassthrough() | SUMMARY_PROMPT | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the final chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableParallel(\n",
    "    case_summary = summary,\n",
    "    question = RunnablePassthrough()\n",
    ")\n",
    "\n",
    "chain = inputs | QUESTION_PROMPT | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided case summary describes a male child with sudden onset paralysis and a history of headaches.  However, crucial information is missing to determine the cause.  The location and extent of the paralysis, the characteristics of the headaches, the temporal relationship between the headaches and paralysis, past medical history, family history, physical examination findings, and results of investigations are all unspecified.  Therefore, a diagnosis and management plan cannot be formulated without this missing information.  The differential diagnosis includes a wide range of possibilities, including stroke, demyelinating diseases, Guillain-Barr√© syndrome, transverse myelitis, intracranial hemorrhage, brain tumor, and infections.  Further investigation is absolutely necessary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": \"Sudden Paralysis in a Boy With Headaches\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
