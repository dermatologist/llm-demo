{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including GoogleGenerativeAI and PromptTemplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the GoogleGenerativeAI model\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Language Model\n",
    "Initialize the language model with the specified model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model with the specified model name\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Prompt Template\n",
    "Define the prompt template with context information and query placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template with context information and query placeholders\n",
    "TEMPLATE = \"\"\"\n",
    "Context information is below.\n",
    " --------------------\n",
    " Katie presents today's session feeling “depressed.” She states that her mood has been “getting worse.”\n",
    " She reports that she has been struggling to get out of the house to enjoy social events that she is actually interested in,\n",
    " then becomes more frustrated with herself. She describes an increase in sleep issues,\n",
    " both difficulty falling asleep and staying asleep. Katie says that she “just wants to be better.”\n",
    " Katie continues to endorse low energy, loss of interest in activities, difficulty sleeping, and feelings of guilt,\n",
    " although she is not able to express the source of her guilt.\n",
    " --------------------\n",
    " Given the context information and not prior knowledge, answer the query.\n",
    " Query: {question}\n",
    "\n",
    " Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object from the defined template\n",
    "PROMPT = PromptTemplate.from_template(TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple chain\n",
    "Create a dictionary to hold the input question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Input Dictionary\n",
    "\n",
    "# Define the input dictionary with a sample question\n",
    "_input = {\n",
    "    \"question\": \"What are Katie's complaints?\"\n",
    "}\n",
    "\n",
    "chain = PROMPT | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Response\n",
    "Use the language model and prompt template to generate a response based on the input question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katie's complaints include feeling depressed with worsening mood, difficulty leaving the house to attend social events she's interested in (leading to self-frustration), increased sleep problems (both falling asleep and staying asleep), low energy, loss of interest in activities, feelings of guilt (though the source is unclear), and a general desire to feel better.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Response\n",
    "\n",
    "# Use the language model and prompt template to generate a response based on the input question\n",
    "response = chain.invoke(_input)\n",
    "\n",
    "# Print the generated response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
